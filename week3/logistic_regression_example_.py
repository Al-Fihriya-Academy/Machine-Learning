# -*- coding: utf-8 -*-
"""Logistic Regression Example .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UXossZzU5EWWXDkjKON6o3HAVz8gIKGS
"""

# Importing pandas and numpy and datasets
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt 
import seaborn as sns    
from  sklearn import  datasets

"""### Lmoustala7at 

__Data:__ Les donnees li 3endna. Koula ster f data dialna katsema observations. F had l7ala, koula werda sejelna katsema observation. 

__Target:__ la colonne li bghina npredictiou. F had l7ala, bghina n3errfou ash nahoua nou3 dial l werda bla manchoufouha.

__Features:__ Les colonnes li bghina nesta3mlou bash n predictiou. F had l7ala, bghina nesta3mlou chi me3loumate 3la lwerda ou n 3erfou ash nahoua nou3 dialha. Dik l me3loumate hia l features.
"""

# Reading the csv file into a pandas DataFrame
iris=datasets.load_iris()
data = pd.DataFrame(data= np.c_[iris['data'], iris['target']],columns= iris['feature_names'] + ['target'])

# 3endna 3 dial anwa3 dial werdate  (werda 0, werda 1, werda 2)
data.target.unique()

# bash nsehlou had l example, hadi nkheliou hir jouj anwa3 dial werdate (werda 0 et werda 1)
data = data[data['target'].isin([0,1])]

# nchoufou data dialna kidayra 
data.head(10)

# nebdaou nesta3mlou hir had les 2 features bash nsehlou 
data = data[['petal length (cm)', 'petal width (cm)', 'target']]

data.head(3)

# nchoufou ch7al men elements f had la data 
print(data.shape)

"""__Summary 1__:

had sa3a, dekhelna la data dialna l notebook. 
- Chefna ch7al men target 3endna, l9ina 3 (werda de type 0, werda de type 1 et werda de type 2). 9ererna f l exemple ndiour tesnife hir dial werda 0 contre werda 1. Redina lproblem "binary classification".
- 3enda 4 dial features f data dialna, et 3awtani bash nsehlou l m2oumouria kter f had l exemple, khdina hir 2 dial features. 'petal length' et 'petal width'. 
- Chefna data dialna fiha 100 observations.

## nfhemou target dialna
"""

# ch7al men element 3endna 
data['target'].value_counts()

"""## nfhemou features dialna mezyane"""

# nbdaou b petal length 

# boxplot 
plt.boxplot(data['petal length (cm)'], vert=False)
plt.xlabel('petal length')
plt.show()

# histogram 
plt.hist(data['petal length (cm)'])
plt.xlabel('petal length')
plt.show()

# nchoufou petal width

# boxplot 
plt.boxplot(data['petal width (cm)'], vert=False)
plt.xlabel('Petal width')
plt.show()

# histogram 
plt.hist(data['petal width (cm)'])
plt.xlabel('Petal width')
plt.show()

"""__Summary 2__: 

Jbedna target dialna et koula feature ou bghina n3erfou ki dayrine. 

- l9ina bi ana target dialna me9souma mezzyane: 3endna 50 observations dial werda 0 et 50 observation dial werda 1. Hada men a7ssan ma yakoune. 
- Chefna la distribution dial l features dialna b jouj dial les plot: boxplot et histogram. Par example, chefna bi 2ana les observations f _"petal length"_ heterogenes (ye3ni ana kaynin bzaf dial les observations f wahd l interval [1, 2] et bzaf d les observations f l interval [3, 5] ou presque pas d observations f l interval [2, 3]. Hadchi kaygoul line bi ana kayna wahd tefri9a li ymken lina ndirou ma bine lwerdate b jouj.

### Nfehmou l3ala9a binathoum
"""

data.head(3)

# njebdou houa louwel data li 3endhoum target = 0 
target_0 = data[data.target == 0]
# mplotti 'petal length (cm)' et 'petal width (cm)' bash nchoufou l3ala9a mabin had l features ou target dialna 
plt.scatter(target_0['petal length (cm)'], target_0['petal width (cm)'], color='blue', label='target 0')

# ndirou nafss chay2 l target 1 
target_1 = data[data.target == 1]
plt.scatter(target_1['petal length (cm)'], target_1['petal width (cm)'], color='red', label='target 1')

plt.legend()
plt.xlabel('petal length (cm)')
plt.ylabel('petal width (cm)')

plt.show()

"""__Summary 3:__

Puisque 3enda hir deux features, tmekena ana n resmou data dialna f had l graph. Had lgraph kaytsema "scatter plot". Fash plotinahoum, bane lina bi 2ana werda 0 et werda 1 mfrou9ine mezyane. Werda 1 (7emrine) 3end petalate kbar f toul (petal length) ou kbar f l 3erd (petal width). Par contre, l werdate 0 3endhoum petalate sghar f toul ou sghar f l3erd. 

Daba bghina n sen3ou l modele li yfre9houm lina rassou. Hadi nsta3mlou Logistic Regression.

## randomize data
"""

# nradomiziou data dialna (randomizi kate3ni katkhelet data dialka, aw bi ma3na akher kadmessha b7al l carta)
data = data.sample(frac=1, random_state = 42)

"""### n9essmou data l training ou testing"""

# blast manketbou la fonction dialna, nsta3mlou wehda wajda men library sklearn 
from sklearn.model_selection import train_test_split

data_train, data_test = train_test_split(data, test_size=0.2)

# 3endna 100 observations f la data kamla
print(data.shape)

# 3endna 80 observations f training data
print(data_train.shape)

# 3endna 20 observations f training data
print(data_test.shape)

# nchoufou data ta3na 3awtani 
plt.scatter(data_train['petal length (cm)'], data_train['petal width (cm)'], color='red', label='training')
plt.scatter(data_test['petal length (cm)'], data_test['petal width (cm)'], color='green', label='testing')

plt.legend()
plt.xlabel('petal length (cm)')
plt.ylabel('petal width (cm)')

plt.show()

"""### train logistic regression"""

# n9essmou data l features et target 
X_train = data_train[['petal length (cm)', 'petal width (cm)']]
y_train = data_train['target']


X_test = data_test[['petal length (cm)', 'petal width (cm)']]
y_test = data_test['target']

from sklearn.linear_model import LogisticRegression
# kan sen3ou l object dial logistic regression
logisticRegr = LogisticRegression()
# kan 3etiouh la data dialna bash yt3elem 
logisticRegr.fit(X_train, y_train)

"""### Nchoufou chnou logistic regression kate3tina

Ntfekrou la formule dial logistic regression 

$$p(y=1|x; \theta) = \frac{1}{1 + e^{\theta_0 + \theta_1 x_1 + \theta_2 x_2}}$$

N9elbou ha bash nel9aou 

$$\theta_0 + \theta_1 x_1 + \theta_2 x_2 = log(\frac{p}{1-p})$$

lmou3adala dial mousta9im hiya 
$$\theta_0 + \theta_1 x_1 + \theta_2 x_2 = 0$$ 

That is, 

$$x_2 = \frac{1}{\theta_2} (\theta_0 + \theta_1 x_1)$$
"""

# nchoufou had les coefficients (theta_0, theta_1, theta_2)
logisticRegr.coef_

# intercept hiya theta_0 
logisticRegr.intercept_

theta_0 = logisticRegr.intercept_[0]
theta_1 = logisticRegr.coef_[0, 0]
theta_2 = logisticRegr.coef_[0, 1]

# decision bondary hiya lmousta9im li kayfre9 lina target mabine 0 et 1 

# nressmou decision boundary dialna 
def decision_boundary(theta_0, theta_1, theta_2, l_x):
    return 1 / theta_2 * (-theta_0 -theta_1 * l_x)

# njebdou houa louwel data li 3endhoum target = 0 
target_0 = data[data.target == 0]
# mplotti 'petal length (cm)' et 'petal width (cm)' bash nchoufou l3ala9a mabin had l features ou target dialna 
plt.scatter(target_0['petal length (cm)'], target_0['petal width (cm)'], color='blue', label='target 0')

# ndirou nafss chay2 l target 1 
target_1 = data[data.target == 1]
plt.scatter(target_1['petal length (cm)'], target_1['petal width (cm)'], color='red', label='target 1')

# nzidou decision boundary 
l_x = np.linspace(1, 5)
l_y = decision_boundary(theta_0, theta_1, theta_2, l_x)
plt.plot(l_x, l_y, label='decision boundary')

plt.legend()
plt.xlabel('petal length (cm)')
plt.ylabel('petal width (cm)')

plt.show()

"""### Wash mezyane had l model li gadina

Kaynine bezaf dial les methodes bash to measure the performance of your model. 

Anhderou 3la hadou: 
- Confusion Matrix 
- Accuracy 
- Precision 
- Recall

#### Confusion Matrix

[<img src="https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg">]

__TN (True Negative)__:  I Predict target=0 et fl7a9i9a hiya target=0

__TP (True Positive)__:  I Predict target=1 et fl7a9i9a hiya target=1

__FN (False Negative)__: I Predict target=0 et fl7a9i9a hiya target=1

__FP (False Positive)__: I Predict target=1 et fl7a9i9a hiya target=0
"""

# nchoufou predictions diawlna 
y_pred = logisticRegr.predict(X_test)

print('predictions: {}'.format(y_pred))
print('true: {}'.format(list(y_test.astype(int))))

from sklearn.metrics import confusion_matrix
# confusion matrix 
cm = confusion_matrix(y_true=y_test, y_pred=y_pred)

# n9adouha bash tbane zwina 

ax= plt.subplot()
sns.heatmap(cm, annot=True, ax = ax, cbar=False)

# labels, title and ticks
ax.set_xlabel('Predicted labels')
ax.set_ylabel('True labels')
ax.set_title('Confusion Matrix')
ax.xaxis.set_ticklabels(['target=0', 'target=1'])
ax.yaxis.set_ticklabels(['target=0', 'target=1'])
plt.show()

# true negative 
TN = 10
# true positive 
TP = 10
# false negative 
FN = 0 
# false positive 
FP = 0

"""#### Accuracy 

Accuracy hiya l pourcentage dial 2ajwiba s7i7a 

$$\text{Accuracy} = \frac{\text{Ajwiba s7i7a}}{\text{Koulchi l 2ajwiba}}$$


Ashnahoua l2ajwiba s7i7a? 

Ajwiba s7i7a hiya True Positives (TP) and True negatives (TN) 


$$\text{Accuracy (%)} = \frac{TP + TN}{TP + FP + TN + FN} * 100$$
"""

accuracy = (TN + TP) / (TN + TP + FP + FN) * 100
print(accuracy, '%')

"""#### Precision 

precision: F ga3 douk l merrate li predictina target = 1, ch7al houal pourcentage kan target = 1 f l 7a9i9a 


$$\text{Precision (%)} = \frac{TP}{TP + FP} * 100$$
"""

precision = TP / (TP + FP) * 100
print(precision, '%')

"""#### Recall 

recall: chnahoua l pourcentage men les observations li 3endhoum target=1 fl7a9i9a jebna s7a7 


$$\text{Recall (%)} = \frac{TP}{TP + FN} * 100$$
"""

recall = TP / (TP + FN) * 100
print(recall, '%')

"""__Summary 3__:

Daba derna wahd le tour sghiwer 3la les bases dial les problems dial classification. 
- bdina dekhelna la data dialna notebook 
- khdina hir les features li bghina ou segherna l probleme dialna l binary classification 
- chefna la distribution dial data ou l9ina bi ana kayna wahd tefri9a f la data li ymken lina nstaghlou 
- 9ssemna data dialna l training ou testing 
- sne3na l model dialna using Logistic Regression 
- chefna l performance dial model dialna 

l9ina bi 2ana l performance dialna 100% f koulchi walakine khassekoum t3erfou bi ana had l problem hada sahel bzaf. Les problemes f l7a9i9a kaykounou chwiya 9ass7ine 3la hadchi ou souvent makatkounch 3endek 100% performance. Ila l9iti rassek derti un model parfait, kaykhessek t9eleleb yakma derti chi mouchkil f chi blassa.
"""

